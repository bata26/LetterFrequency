2024-06-22 10:28:56,511 INFO client.RMProxy: Connecting to ResourceManager at hadoop-namenode/10.1.1.82:8032
2024-06-22 10:28:57,004 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-06-22 10:28:57,029 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1719047139394_0019
2024-06-22 10:28:57,146 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-06-22 10:28:57,337 INFO input.FileInputFormat: Total input files to process : 1
2024-06-22 10:28:57,376 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-06-22 10:28:57,416 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1257)
	at java.lang.Thread.join(Thread.java:1331)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2024-06-22 10:28:57,430 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-06-22 10:28:57,445 INFO mapreduce.JobSubmitter: number of splits:1
2024-06-22 10:28:57,562 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-06-22 10:28:57,602 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1719047139394_0019
2024-06-22 10:28:57,603 INFO mapreduce.JobSubmitter: Executing with tokens: []
2024-06-22 10:28:57,778 INFO conf.Configuration: resource-types.xml not found
2024-06-22 10:28:57,779 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2024-06-22 10:28:57,852 INFO impl.YarnClientImpl: Submitted application application_1719047139394_0019
2024-06-22 10:28:57,898 INFO mapreduce.Job: The url to track the job: http://hadoop-namenode:8088/proxy/application_1719047139394_0019/
2024-06-22 10:28:57,899 INFO mapreduce.Job: Running job: job_1719047139394_0019
2024-06-22 10:29:04,074 INFO mapreduce.Job: Job job_1719047139394_0019 running in uber mode : false
2024-06-22 10:29:04,076 INFO mapreduce.Job:  map 0% reduce 0%
2024-06-22 10:29:21,403 INFO mapreduce.Job:  map 25% reduce 0%
2024-06-22 10:29:27,476 INFO mapreduce.Job:  map 35% reduce 0%
2024-06-22 10:29:33,537 INFO mapreduce.Job:  map 46% reduce 0%
2024-06-22 10:29:39,598 INFO mapreduce.Job:  map 56% reduce 0%
2024-06-22 10:29:45,676 INFO mapreduce.Job:  map 100% reduce 0%
2024-06-22 10:29:57,767 INFO mapreduce.Job:  map 100% reduce 10%
2024-06-22 10:30:00,800 INFO mapreduce.Job:  map 100% reduce 15%
2024-06-22 10:30:01,823 INFO mapreduce.Job:  map 100% reduce 20%
2024-06-22 10:30:02,831 INFO mapreduce.Job:  map 100% reduce 30%
2024-06-22 10:30:06,875 INFO mapreduce.Job:  map 100% reduce 35%
2024-06-22 10:30:08,889 INFO mapreduce.Job:  map 100% reduce 40%
2024-06-22 10:30:09,898 INFO mapreduce.Job:  map 100% reduce 45%
2024-06-22 10:30:10,905 INFO mapreduce.Job:  map 100% reduce 55%
2024-06-22 10:30:13,922 INFO mapreduce.Job:  map 100% reduce 60%
2024-06-22 10:30:14,940 INFO mapreduce.Job:  map 100% reduce 65%
2024-06-22 10:30:15,947 INFO mapreduce.Job:  map 100% reduce 75%
2024-06-22 10:30:18,969 INFO mapreduce.Job:  map 100% reduce 85%
2024-06-22 10:30:20,993 INFO mapreduce.Job:  map 100% reduce 95%
2024-06-22 10:30:22,002 INFO mapreduce.Job:  map 100% reduce 100%
2024-06-22 10:30:22,020 INFO mapreduce.Job: Job job_1719047139394_0019 completed successfully
2024-06-22 10:30:22,114 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=36582
		FILE: Number of bytes written=4578734
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=52428916
		HDFS: Number of bytes written=264
		HDFS: Number of read operations=103
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=40
	Job Counters 
		Killed reduce tasks=1
		Launched map tasks=1
		Launched reduce tasks=21
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=77616
		Total time spent by all reduces in occupied slots (ms)=520416
		Total time spent by all map tasks (ms)=38808
		Total time spent by all reduce tasks (ms)=260208
		Total vcore-milliseconds taken by all map tasks=38808
		Total vcore-milliseconds taken by all reduce tasks=260208
		Total megabyte-milliseconds taken by all map tasks=9934848
		Total megabyte-milliseconds taken by all reduce tasks=66613248
	Map-Reduce Framework
		Map input records=318178
		Map output records=41731198
		Map output bytes=250387188
		Map output materialized bytes=312
		Input split bytes=116
		Combine input records=41731462
		Combine output records=288
		Reduce input groups=24
		Reduce shuffle bytes=312
		Reduce input records=24
		Reduce output records=24
		Spilled Records=360
		Shuffled Maps =20
		Failed Shuffles=0
		Merged Map outputs=20
		GC time elapsed (ms)=8157
		CPU time spent (ms)=78370
		Physical memory (bytes) snapshot=4025679872
		Virtual memory (bytes) snapshot=39623790592
		Total committed heap usage (bytes)=2501902336
		Peak Map Physical memory (bytes)=280256512
		Peak Map Virtual memory (bytes)=1870999552
		Peak Reduce Physical memory (bytes)=199081984
		Peak Reduce Virtual memory (bytes)=1897226240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	it.unipi.hadoop.mapper.LetterFrequencyMapper$LetterCounter
		TOTAL_LETTERS=41731198
	File Input Format Counters 
		Bytes Read=52428800
	File Output Format Counters 
		Bytes Written=264
waiting for killing container....
